{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to import all necessary components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from src.ats import *\n",
    "import pandas as pd\n",
    "from src.print_ats import *\n",
    "from src.input_data import InputData\n",
    "from src.custom_models import Average, Minimum, Maximum, SampleMean, Median, Mode\n",
    "from sklearn.linear_model import (\n",
    "    LinearRegression,\n",
    "    LogisticRegression,\n",
    "    ElasticNetCV,\n",
    ")\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor, RandomForestRegressor\n",
    "from src.helper import print_progress_bar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can make our model, we need to apply pre-pocessing first. This can be done via the inputData class that is dedicated for the given data. Many of the well-known pre-processing functionality is implemented. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "START PREPROCESSING\n",
      "Filtering out incomplete processes.. [1632 rows have been deleted...]\n",
      "Converting dates.. \n",
      "Adding remaining time attribute..\n",
      "Encoding columns ['Service Affected', 'Asset Affected', 'Asset SubType Affected', 'Service Caused', 'Assignment Group', 'Priority', 'Asset Type Affected', 'Category', 'Status', 'Closure Code', 'Asset Caused', 'Asset Type Caused', 'Asset SubType Caused'] using none encoding..\n",
      "Adding previous events attribute..\n"
     ]
    }
   ],
   "source": [
    "ALL_DATE_COLS = [\n",
    "    \"ActivityTimeStamp\",\n",
    "    \"Open Time\",\n",
    "    \"Reopen Time\",\n",
    "    \"Resolved Time\",\n",
    "    \"Close Time\",\n",
    "]\n",
    "\n",
    "input = InputData(\"incidentProcess_custom.csv\")\n",
    "input.apply_standard_preprocessing(\n",
    "    agg_col=\"rem_time\",  # calculated y column\n",
    "    filter_incompletes=True, #Only complete traces (i.e., that start and finish in the given data set) are included\n",
    "    dropna=False,\n",
    "    date_cols=ALL_DATE_COLS,  # list of cols that must be transformed into unix time. If empty / not given, nothing will be transformed\n",
    ")\n",
    "\n",
    "# # columns that have have ordinal values are label encoded\n",
    "# input.use_cat_encoding_on(\"label\", [\"Category\", \"Activity\"])\n",
    "\n",
    "# columns with too many categories are deleted\n",
    "input.use_cat_encoding_on(\n",
    "    \"none\",\n",
    "    [\n",
    "        \"Service Affected\",\n",
    "        \"Asset Affected\",\n",
    "        \"Asset SubType Affected\",\n",
    "        \"Service Caused\",\n",
    "        \"Assignment Group\",\n",
    "        \"Priority\",\n",
    "        \"Asset Type Affected\",\n",
    "        \"Category\",\n",
    "        \"Status\",\n",
    "        \"Closure Code\",\n",
    "        \"Asset Caused\",\n",
    "        \"Asset Type Caused\",\n",
    "        \"Asset SubType Caused\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "\n",
    "# split function that keeps traces together\n",
    "X_train, X_test, y_train, y_test = input.train_test_split_on_trace(\n",
    "    y_col=\"RemainingTime\", ratio=0.8\n",
    ")\n",
    "\n",
    "# The previous event attribute must be added in order to navigate through the ATS.\n",
    "X_test = input.add_prev_events(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START CREATING ATS\n",
      "Create: |XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX| 100.0% Complete\n",
      "\n",
      "\n",
      "Finalize: |XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX| 100.0% Complete\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ats = ATS(\n",
    "    trace_id_col=\"Incident ID\",\n",
    "    act_col=\"Activity\",\n",
    "    y_col=\"RemainingTime\",\n",
    "    representation=\"multiset\",\n",
    "    horizon=1,\n",
    "    model=HistGradientBoostingRegressor()\n",
    ")\n",
    "\n",
    "ats.fit(X_train, y_train)\n",
    "ats.finalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now test the accuracy of our model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: |XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX| 100.0% Complete\n",
      "MAE: 58 hours  = 2 days\n"
     ]
    }
   ],
   "source": [
    "diff = 0.0\n",
    "\n",
    "print_progress_bar(\n",
    "    0, len(y_test), prefix=\"Prediction:\", suffix=\"Complete\", length=50\n",
    ")\n",
    "\n",
    "\n",
    "for i, event in enumerate(X_test.to_dict(orient=\"records\")):\n",
    "\n",
    "    y_pred = ats.predict(event)\n",
    "\n",
    "    diff += abs(y_pred - y_test.iloc[i])\n",
    "\n",
    "    print_progress_bar(\n",
    "        i+1, len(y_test), prefix=\"Prediction:\", suffix=\"Complete\", length=50\n",
    "    )\n",
    "\n",
    "diff = diff / len(y_test)\n",
    "\n",
    "print(f\"MAE: {round(diff / (60*60))} hours  = {round(diff / (60*60*24))} days\") #get difference in hours instead of seconds\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d58c946d523da25b67c9c710fb95a4d23a654dcfdb423986d06f0a6f7387888f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
